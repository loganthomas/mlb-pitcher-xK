{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7db779-c654-4d55-84e0-4c66485f9f9f",
   "metadata": {},
   "source": [
    "# Model Training - Classic Cross-Validation\n",
    "\n",
    "Various combinations of model architectures, features, and training approaches were tested (since the baseline models' performance isn't expected to change, they won't be tested in this notebook).\n",
    "\n",
    "## Model Architectures\n",
    "1. **Baseline Model (avg)**: Predict the average `'K%'` across a pitcher's available data.\n",
    "2. **Baseline Model (last)**: Predict the last observed `'K%'` from the pitcher's available data.\n",
    "3. **Baseline Model (xK%)**: Predict `'K%'` using the formula: `xK% = -0.61 + (L/Str * 1.1538) + (S/Str * 1.4696) + (F/Str * 0.9417)` (see [The Definitive Pitcher Expected K% Formula](https://fantasy.fangraphs.com/the-definitive-pitcher-expected-k-formula/)).\n",
    "4. [**Linear Regression Model**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "5. [**Random Forest Model**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "6. [**XGBoost Model**](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)\n",
    "\n",
    "## Features\n",
    "1. **All 67 Features**:\n",
    "    - 31 categorical one-hot encoded features for teams (30 MLB teams plus `'---'` for multi-team).\n",
    "    - 36 numeric features.\n",
    "2. **7 Features Selected from Lasso Model** (see [03-feature-engineering.ipynb](./03-feature-engineering.ipynb)):\n",
    "    - `'numeric__Pit/PA'`\n",
    "    - `'numeric__Str%'`\n",
    "    - `'numeric__F/Str'`\n",
    "    - `'numeric__I/Str'`\n",
    "    - `'numeric__Con'`\n",
    "    - `'numeric__30%'`\n",
    "    - `'numeric__L/SO'`\n",
    "\n",
    "## Training Approach\n",
    "Two training schemas will be utilized for model training, with **MSE** (mean squared error) used to evaluate model performance:\n",
    "1. **Classical Cross-Validation**: The data will be split into K-folds, with the goal of predicting `'K%'`.\n",
    "2. **Time-Series Cross-Validation**: Folds will be based on the season, using earlier years (e.g., `2021`) to predict subsequent years (e.g., `2022`), and so on (e.g., `2021-2022` to predict `2023`).\n",
    "\n",
    "**THIS NOTEBOOK USES THE TIME-SERIES CROSS-VALIDATION APPROACH**\n",
    "- For more details, refer to [02-data-partitioning.ipynb](./02-data-partitioning.ipynb).\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"Player Pool\"]\n",
    "    A --> B[\"Training Pool\"]\n",
    "    \n",
    "    subgraph TrainingFlow [\" \"]\n",
    "        direction LR\n",
    "        D[\"2021 --- 2022 --- 2023 \"]\n",
    "        F[\"X 2024\"]:::red\n",
    "    end\n",
    "    B -- Training Flow --> D\n",
    "\n",
    "    \n",
    "    subgraph CVTimeSeries [\"TimeSeries CV: Previous year predicts next year's K%\"]\n",
    "        FoldTitle11[\"Fold1\"]:::noBorder\n",
    "        FoldTitle22[\"Fold2\"]:::noBorder\n",
    "        FoldTitle33[\"Fold3\"]:::noBorder\n",
    "\n",
    "        Split11[\"Split1\"]:::noBorder\n",
    "        Fold11[\"2021\"]:::green\n",
    "        Fold22[\"2022\"]:::blue\n",
    "        Fold33[\"2023\"]:::transparent\n",
    "        \n",
    "        Split22[\"Split2\"]:::noBorder\n",
    "        Fold44[\"2021\"]:::green\n",
    "        Fold55[\"2022\"]:::green\n",
    "        Fold66[\"2023\"]:::blue\n",
    "        \n",
    "        Split33[\"Split3\"]:::transparent\n",
    "        Fold77[\"Fold1\"]:::transparent\n",
    "        Fold88[\"Fold2\"]:::transparent\n",
    "        Fold99[\"Fold3\"]:::transparent\n",
    "        \n",
    "        FoldTitle11 ~~~ Fold11\n",
    "        FoldTitle22 ~~~ Fold22\n",
    "        FoldTitle33 ~~~ Fold33\n",
    "        \n",
    "        Split11 ~~~ Split22\n",
    "        Split22 ~~~ Split33\n",
    "\n",
    "        Fold11 ~~~ Fold44\n",
    "        Fold22 ~~~ Fold55\n",
    "        Fold33 ~~~ Fold66\n",
    "\n",
    "        Fold44 ~~~ Fold77\n",
    "        Fold55 ~~~ Fold88\n",
    "        Fold66 ~~~ Fold99\n",
    "    end\n",
    "\n",
    "    TrainingFlow --> CVTimeSeries\n",
    "\n",
    "    classDef red fill:#FFCCCC,stroke:#FF0000,stroke-width:2px;\n",
    "    classDef green fill:#CCFFCC,stroke:#00FF00,stroke-width:2px;\n",
    "    classDef blue fill:#CCCCFF,stroke:#0000FF,stroke-width:2px;\n",
    "    classDef noBorder fill:none,stroke:none,color:#000000;\n",
    "    classDef transparent fill:#FFFFFF,stroke:#FFFFFF,stroke-width:2px,opacity:0;\n",
    "```\n",
    "\n",
    "Inspired by scikit-learn:\n",
    "- https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "- https://scikit-learn.org/1.5/modules/cross_validation.html#time-series-split\n",
    "\n",
    "--- \n",
    "## Development Workflow\n",
    "\n",
    "All functions and pipelines demonstrated in this notebook are defined in the `bullpen.data_utils` and `bullpen.model_utils` modules for clarity, reusability, and unit testing. While this notebook retains the initial development and intent of these functions, their inclusion here is primarily for transparency and ease of reference.  \n",
    "\n",
    "For production usage, refer to the source code in the `bullpen.data_utils` and `bullpen.model_utils` modules.\n",
    "\n",
    "# Model Training - Time Series Cross-Validation\n",
    "A number combination of different model architectures, features used, and training approaches were tested in the [04a-modeling-classic-cv.ipynb](./04a-modeling-classic-cv.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85256d7-1e37-4b55-afd4-b5680fcdee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.stats\n",
    "import xgboost as xgb\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "set_config(display=\"text\")\n",
    "\n",
    "from bullpen import data_utils, model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cde23de-d20f-4e98-a132-df6b9e1fe99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>MLBAMID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>TBF</th>\n",
       "      <th>K%</th>\n",
       "      <th>Rk</th>\n",
       "      <th>IP</th>\n",
       "      <th>...</th>\n",
       "      <th>02s</th>\n",
       "      <th>02h</th>\n",
       "      <th>L/SO</th>\n",
       "      <th>S/SO</th>\n",
       "      <th>L/SO%</th>\n",
       "      <th>3pK</th>\n",
       "      <th>4pW</th>\n",
       "      <th>PAu</th>\n",
       "      <th>Pitu</th>\n",
       "      <th>Stru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18655</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2021</td>\n",
       "      <td>621345</td>\n",
       "      <td>A.J. Minter</td>\n",
       "      <td>27</td>\n",
       "      <td>221</td>\n",
       "      <td>0.257919</td>\n",
       "      <td>696</td>\n",
       "      <td>52.1</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>0.193</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18655</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2022</td>\n",
       "      <td>621345</td>\n",
       "      <td>A.J. Minter</td>\n",
       "      <td>28</td>\n",
       "      <td>271</td>\n",
       "      <td>0.346863</td>\n",
       "      <td>649</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "      <td>0.245</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18655</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2023</td>\n",
       "      <td>621345</td>\n",
       "      <td>A.J. Minter</td>\n",
       "      <td>29</td>\n",
       "      <td>260</td>\n",
       "      <td>0.315385</td>\n",
       "      <td>647</td>\n",
       "      <td>64.2</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>0.159</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19343</td>\n",
       "      <td>OAK</td>\n",
       "      <td>2022</td>\n",
       "      <td>640462</td>\n",
       "      <td>A.J. Puk</td>\n",
       "      <td>27</td>\n",
       "      <td>281</td>\n",
       "      <td>0.270463</td>\n",
       "      <td>773</td>\n",
       "      <td>66.1</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>0.289</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19343</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023</td>\n",
       "      <td>640462</td>\n",
       "      <td>A.J. Puk</td>\n",
       "      <td>28</td>\n",
       "      <td>242</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>755</td>\n",
       "      <td>56.2</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>0.282</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>1943</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2021</td>\n",
       "      <td>425844</td>\n",
       "      <td>Zack Greinke</td>\n",
       "      <td>37</td>\n",
       "      <td>697</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>417</td>\n",
       "      <td>171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>85</td>\n",
       "      <td>0.283</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>1943</td>\n",
       "      <td>KCR</td>\n",
       "      <td>2022</td>\n",
       "      <td>425844</td>\n",
       "      <td>Zack Greinke</td>\n",
       "      <td>38</td>\n",
       "      <td>585</td>\n",
       "      <td>0.124786</td>\n",
       "      <td>396</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>0.301</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1943</td>\n",
       "      <td>KCR</td>\n",
       "      <td>2023</td>\n",
       "      <td>425844</td>\n",
       "      <td>Zack Greinke</td>\n",
       "      <td>39</td>\n",
       "      <td>593</td>\n",
       "      <td>0.163575</td>\n",
       "      <td>353</td>\n",
       "      <td>142.1</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>0.263</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>25918</td>\n",
       "      <td>STL</td>\n",
       "      <td>2022</td>\n",
       "      <td>668868</td>\n",
       "      <td>Zack Thompson</td>\n",
       "      <td>24</td>\n",
       "      <td>136</td>\n",
       "      <td>0.198529</td>\n",
       "      <td>967</td>\n",
       "      <td>34.2</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0.370</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>25918</td>\n",
       "      <td>STL</td>\n",
       "      <td>2023</td>\n",
       "      <td>668868</td>\n",
       "      <td>Zack Thompson</td>\n",
       "      <td>25</td>\n",
       "      <td>287</td>\n",
       "      <td>0.250871</td>\n",
       "      <td>942</td>\n",
       "      <td>66.1</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "      <td>0.324</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PlayerId Team  Season  MLBAMID           Name  Age  TBF        K%   Rk  \\\n",
       "0       18655  ATL    2021   621345    A.J. Minter   27  221  0.257919  696   \n",
       "1       18655  ATL    2022   621345    A.J. Minter   28  271  0.346863  649   \n",
       "2       18655  ATL    2023   621345    A.J. Minter   29  260  0.315385  647   \n",
       "3       19343  OAK    2022   640462       A.J. Puk   27  281  0.270463  773   \n",
       "4       19343  MIA    2023   640462       A.J. Puk   28  242  0.322314  755   \n",
       "..        ...  ...     ...      ...            ...  ...  ...       ...  ...   \n",
       "983      1943  HOU    2021   425844   Zack Greinke   37  697  0.172166  417   \n",
       "984      1943  KCR    2022   425844   Zack Greinke   38  585  0.124786  396   \n",
       "985      1943  KCR    2023   425844   Zack Greinke   39  593  0.163575  353   \n",
       "986     25918  STL    2022   668868  Zack Thompson   24  136  0.198529  967   \n",
       "987     25918  STL    2023   668868  Zack Thompson   25  287  0.250871  942   \n",
       "\n",
       "        IP  ...  02s  02h  L/SO  S/SO  L/SO%  3pK  4pW  PAu  Pitu  Stru  \n",
       "0     52.1  ...   44    7    11    46  0.193   11    4    0     0     0  \n",
       "1     70.0  ...   50    2    23    71  0.245   12    0    0     0     0  \n",
       "2     64.2  ...   40    4    13    69  0.159    8    1    0     0     0  \n",
       "3     66.1  ...   48    6    22    54  0.289   15    4    0     0     0  \n",
       "4     56.2  ...   42    6    22    56  0.282   16    0    0     0     0  \n",
       "..     ...  ...  ...  ...   ...   ...    ...  ...  ...  ...   ...   ...  \n",
       "983  171.0  ...   51    4    34    85  0.283   13    6    0     0     0  \n",
       "984  137.0  ...   39    3    22    51  0.301    7    2    0     0     0  \n",
       "985  142.1  ...   53    6    25    70  0.263   11    2    0     0     0  \n",
       "986   34.2  ...   40    3    10    17  0.370    3    2    0     0     0  \n",
       "987   66.1  ...   43    2    23    48  0.324   12    4    0     0     0  \n",
       "\n",
       "[988 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_utils.DATA_DIR.joinpath(\"train.csv\"))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bd39f4-fd25-41fd-9a2f-35b0f7672bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2021, 2022, 2023]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_list = train_df.Season.unique().tolist()\n",
    "year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5aba6a1-8e9b-45dd-9deb-1d4c735c9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_splits(year_list, train_df):\n",
    "    splits = {\"train\": [], \"val\": []}\n",
    "    for idx, year in enumerate(year_list[:-1]):\n",
    "        train_years = year_list[: idx + 1]\n",
    "        val_year = year_list[idx + 1]\n",
    "\n",
    "        print(f\"TRAIN: {train_years} VAL: {[val_year]}\")\n",
    "\n",
    "        splits[\"train\"].append(train_df[train_df[\"Season\"].isin(train_years)])\n",
    "        splits[\"val\"].append(train_df[train_df[\"Season\"] == val_year])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecc4107-bd12-4111-b1af-721ca0eefc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2021] VAL: [2022]\n",
      "TRAIN: [2021, 2022] VAL: [2023]\n"
     ]
    }
   ],
   "source": [
    "splits = make_timeseries_splits(year_list, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457e5ebd-70f8-47a3-8f63-6a59c053e0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2021]), array([2022]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sniff test (split 1)\n",
    "splits[\"train\"][0].Season.unique(), splits[\"val\"][0].Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5fe8de-80c6-4693-b7d5-ec20fab1167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2021, 2022]), array([2023]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sniff test (split 2)\n",
    "splits[\"train\"][1].Season.unique(), splits[\"val\"][1].Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c426b239-4847-446e-aaab-35c87c62fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_X_y(split, target=\"K%\", drop_cols=None):\n",
    "    drop_cols = [\"Name\", target] if drop_cols is None else drop_cols\n",
    "\n",
    "    X_df = split[[c for c in split.columns if c not in drop_cols]]\n",
    "    y_df = split[target]\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d8b5ac-40e3-44e2-b921-0ac68beaa96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = pred_X_y(splits[\"train\"][0])\n",
    "X_val_df, y_val_df = pred_X_y(splits[\"val\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428ef115-3186-461c-a5cc-25959f2eaf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2021]), array([2022]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sniff test\n",
    "X_df.Season.unique(), X_val_df.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb7ad920-0aa7-4db2-a90c-344d5b87a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = pred_X_y(splits[\"train\"][1])\n",
    "X_val_df, y_val_df = pred_X_y(splits[\"val\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e701ca0-dc8a-4cab-af3c-ce6c13170567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2021, 2022]), array([2023]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sniff test\n",
    "X_df.Season.unique(), X_val_df.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d28ddcd-a78d-48b2-93e0-47439fcdc85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('categorical',\n",
       "                                 Pipeline(steps=[('encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['Team']),\n",
       "                                ('numeric',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 ['PlayerId', 'Season', 'MLBAMID', 'Age', 'TBF',\n",
       "                                  'Rk', 'IP', 'PA', 'Pit', 'Pit/PA', 'Str',\n",
       "                                  'Str%', 'L/Str', 'S/Str', 'F/Str', 'I/Str',\n",
       "                                  'AS/Str', 'I/Bll', 'AS/Pit', 'Con', '1st%',\n",
       "                                  '30%', '30c', '30s', '02%', '02c', '02s',\n",
       "                                  '02h', 'L/SO', 'S/SO', ...])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = model_utils.make_processing_pipeline(\n",
    "    categorical_features=[\"Team\"],\n",
    "    numeric_features=[f for f in X_df.columns if f not in (\"Team\")],\n",
    ")\n",
    "\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f90e81a-3f56-4ed0-9026-ba0593349272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('numeric',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 ['Pit/PA', 'Str%', 'F/Str', 'I/Str', 'Con',\n",
       "                                  '30%', 'L/SO'])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features = [\n",
    "    \"Pit/PA\",\n",
    "    \"Str%\",\n",
    "    \"F/Str\",\n",
    "    \"I/Str\",\n",
    "    \"Con\",\n",
    "    \"30%\",\n",
    "    \"L/SO\",\n",
    "]\n",
    "X_df_lasso = X_df[lasso_features]\n",
    "\n",
    "processor_lasso = model_utils.make_processing_pipeline(\n",
    "    categorical_features=None,\n",
    "    numeric_features=list(X_df_lasso.columns),\n",
    ")\n",
    "\n",
    "processor_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157307fa-bac0-47b5-aa22-d275d0e84097",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "### Baseline Estimators\n",
    "Since the baseline models rely solely on the target variable (without incorporating any feature data), and the `ArticleModel` uses raw, unscaled data, these models are excluded from the training process in this notebook. The results of the baseline models are expected to remain consistent, and models trained using the time-series cross-validation approach should outperform these baseline models.\n",
    "\n",
    "| Model                        | R²       | MSE     |\n",
    "|------------------------------|----------|---------|\n",
    "| ArticleModel()               | 0.876    | 0.000396|\n",
    "| Baseline (method='mean')     | 0.835    | 0.000527|\n",
    "| Baseline (method='last')     | 0.673    | 0.001041|\n",
    "\n",
    "### Non-Baseline Estimators\n",
    "With the baseline models established, we proceed with more advanced models, including:\n",
    "1. [Linear Regression Model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "2. [Random Forest Model](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "3. [XGBoost Model](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor)\n",
    "\n",
    "Each of the above model architectures will be tested with two different feature sets:\n",
    "1. **All 67 Features**  \n",
    "   - 31 categorical one-hot features for teams (30 MLB teams and '---' for multi-team)\n",
    "   - 36 numeric features\n",
    "2. **7 Features Selected from Lasso Model** (see [03-feature-engineering.ipynb](./03-feature-engineering.ipynb))\n",
    "   - `'numeric__Pit/PA'`\n",
    "   - `'numeric__Str%'`\n",
    "   - `'numeric__F/Str'`\n",
    "   - `'numeric__I/Str'`\n",
    "   - `'numeric__Con'`\n",
    "   - `'numeric__30%'`\n",
    "   - `'numeric__L/SO'`\n",
    "\n",
    "**Note**: The baseline models do not utilize features; they rely only on the mean or the last observed value of the target variable (`'K%'`). The `ArticleModel` specifically selects columns with the highest predictive power as mentioned in the article. Therefore, testing the performance of the baseline models with the full feature set is unnecessary. For the remaining models, we will evaluate performance using both the full feature set and the Lasso-selected feature set.\n",
    "\n",
    "### Time Series Cross-Validation\n",
    "Previously, we used scikit-learn's `GridSearchCV` class for model tuning and hyperparameter optimization. In this notebook, we will implement a custom training loop to apply a time-series cross-validation scheme, ensuring that models are trained on past data to predict future data, as illustrated below:\n",
    "\n",
    "![Time Series Cross-Validation](../assets/images/time-series-cv.png)  \n",
    "Source: [scikit-learn User Guide](https://scikit-learn.org/1.6/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ecbbe4-05b9-493d-88a5-e3b53d830a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(\n",
    "    model,\n",
    "    param_grid,\n",
    "    splits,\n",
    "    processor,\n",
    "    metric_key=\"mean_mse\",\n",
    "    K=2,\n",
    "    use_lasso_features=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Manual cross-validation based on custom timeseries data\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        print(f\"Testing parameters: {param_dict}\")\n",
    "\n",
    "        split_scores = []\n",
    "        for split_idx in range(K):\n",
    "            # Get training and validation data\n",
    "            X_df, y_df = pred_X_y(splits[\"train\"][split_idx])\n",
    "            X_val_df, y_val_df = pred_X_y(splits[\"val\"][split_idx])\n",
    "            print(f\"TRAIN: {X_df.Season.unique()} VAL: {X_val_df.Season.unique()}\")\n",
    "            \n",
    "            if use_lasso_features:\n",
    "                print(\"Down selecting to Lasso-selected features...\")\n",
    "                X_df = X_df[lasso_features]\n",
    "                X_val_df = X_val_df[lasso_features]\n",
    "            \n",
    "            # Initialize and train the model\n",
    "            preds, metrics = model_utils.train_model(\n",
    "                processor, model(**param_dict), X_df, y_df, results={}, name=\"model\"\n",
    "            )\n",
    "\n",
    "            # Collect the desired metric (e.g., MSE) which is the second, or last appended\n",
    "            split_scores.append(metrics[\"model\"][-1])\n",
    "\n",
    "        # Compute mean metric across splits\n",
    "        mean_metric = np.mean(split_scores)\n",
    "        results.append({**param_dict, metric_key: mean_metric})\n",
    "\n",
    "        print(f\"Mean {metric_key}: {mean_metric:.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Find the best hyperparameters based on the lowest metric\n",
    "    best_result = min(results, key=lambda x: x[metric_key])\n",
    "    return results, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f97f89c-0dbf-41da-a650-74137249ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'fit_intercept': True}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "Down selecting to Lasso-selected features...\n",
      "model params=None score=0.917 mse=0.00026\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "Down selecting to Lasso-selected features...\n",
      "model params=None score=0.930 mse=0.00023\n",
      "Mean mean_mse: 0.0002\n",
      "\n",
      "Testing parameters: {'fit_intercept': False}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "Down selecting to Lasso-selected features...\n",
      "model params=None score=-17.131 mse=0.05642\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "Down selecting to Lasso-selected features...\n",
      "model params=None score=-15.983 mse=0.05547\n",
      "Mean mean_mse: 0.0559\n",
      "\n",
      "Best Hyperparameters for Linear Regression:\n",
      "{'fit_intercept': True, 'mean_mse': 0.00024341758463156652}\n"
     ]
    }
   ],
   "source": [
    "lr_param_grid = {\"fit_intercept\": [True, False]}\n",
    "\n",
    "lr_results, lr_best_result = cross_validate_model(\n",
    "    model=LinearRegression,\n",
    "    param_grid=lr_param_grid,\n",
    "    splits=splits,\n",
    "    processor=processor_lasso,\n",
    "    use_lasso_features=True,\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters for Linear Regression:\")\n",
    "print(lr_best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a220edb-0d69-42ea-87a0-48d7e6d91518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'n_estimators': 25, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.959 mse=0.00013\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.947 mse=0.00017\n",
      "Mean mean_mse: 0.0002\n",
      "\n",
      "Testing parameters: {'n_estimators': 25, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.981 mse=0.00006\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.982 mse=0.00006\n",
      "Mean mean_mse: 0.0001\n",
      "\n",
      "Testing parameters: {'n_estimators': 25, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.979 mse=0.00006\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.985 mse=0.00005\n",
      "Mean mean_mse: 0.0001\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.959 mse=0.00013\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.949 mse=0.00017\n",
      "Mean mean_mse: 0.0001\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.984 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.985 mse=0.00005\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.984 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.986 mse=0.00004\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.959 mse=0.00013\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.949 mse=0.00017\n",
      "Mean mean_mse: 0.0001\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.984 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.985 mse=0.00005\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.984 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.987 mse=0.00004\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.959 mse=0.00013\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.949 mse=0.00017\n",
      "Mean mean_mse: 0.0001\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.984 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.986 mse=0.00005\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.985 mse=0.00005\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.987 mse=0.00004\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Best Hyperparameters for RandomForestRegressor:\n",
      "{'n_estimators': 150, 'max_depth': 15, 'mean_mse': 4.501634366045223e-05}\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\"n_estimators\": [25, 50, 100, 150], \"max_depth\": [5, 10, 15]}\n",
    "\n",
    "rf_results, rf_best_result = cross_validate_model(\n",
    "    model=RandomForestRegressor,\n",
    "    param_grid=rf_param_grid,\n",
    "    splits=splits,\n",
    "    processor=processor,\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters for RandomForestRegressor:\")\n",
    "print(rf_best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e88af24-cd08-44eb-ac87-07da55838af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'n_estimators': 25, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=0.996 mse=0.00001\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.994 mse=0.00002\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 25, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 25, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=0.999 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 50, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 5}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 10}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Testing parameters: {'n_estimators': 150, 'max_depth': 15}\n",
      "TRAIN: [2021] VAL: [2022]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "TRAIN: [2021 2022] VAL: [2023]\n",
      "model params=None score=1.000 mse=0.00000\n",
      "Mean mean_mse: 0.0000\n",
      "\n",
      "Best Hyperparameters for XGBRegressor:\n",
      "{'n_estimators': 150, 'max_depth': 15, 'mean_mse': 1.6873354951003053e-07}\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\"n_estimators\": [25, 50, 100, 150], \"max_depth\": [5, 10, 15]}\n",
    "\n",
    "xgb_results, xgb_best_result = cross_validate_model(\n",
    "    model=xgb.XGBRegressor,\n",
    "    param_grid=xgb_param_grid,\n",
    "    splits=splits,\n",
    "    processor=processor,\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters for XGBRegressor:\")\n",
    "print(xgb_best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892399f1-6599-4885-a01d-1dbfe7c3134c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- All models demonstrated strong performance with Time Series cross-validation. While no significant changes were expected, it was reassuring to confirm this approach's consistency.\n",
    "- Although the tree-based models (`RandomForestRegressor` and `XGBRegressor`) outperformed the linear model in terms of predictive power, the interpretability and simplicity of the linear model remain appealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1887f5-be54-46dd-b796-72f1d32ccfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mse\n",
       "model                          \n",
       "XGBRegressor           0.000000\n",
       "RandomForestRegressor  0.000045\n",
       "LinearRegression       0.000243"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = (\"LinearRegression\", \"RandomForestRegressor\", \"XGBRegressor\")\n",
    "mses = [d[\"mean_mse\"] for d in [lr_best_result, rf_best_result, xgb_best_result]]\n",
    "results_df = (\n",
    "    pd.DataFrame(zip(models, mses), columns=[\"model\", \"mse\"])\n",
    "    .set_index(\"model\")\n",
    "    .sort_values(\"mse\")\n",
    "    .round(6)\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c3a3a-991e-4021-adda-61ba887c2968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
